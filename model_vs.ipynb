{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a5ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93352ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")[['Canonical_Smiles', 'Inhibition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9737ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mol'] = df['Canonical_Smiles'].apply(Chem.MolFromSmiles)\n",
    "df = df[df['mol'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea92328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 556/1681 [00:04<00:07, 157.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1316/1681 [00:09<00:01, 188.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1681/1681 [00:12<00:00, 129.54it/s]\n"
     ]
    }
   ],
   "source": [
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "desc = calc.pandas(df['mol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbe4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 숫자형 컬럼만 추출\n",
    "desc_numeric = desc.select_dtypes(include=[np.number])\n",
    "\n",
    "# 2. 전부 NaN인 열 제거\n",
    "desc_numeric = desc_numeric.dropna(axis=1, how='all')\n",
    "\n",
    "# 3. 중앙값으로 NaN 처리\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "desc_imputed_array = imputer.fit_transform(desc_numeric)\n",
    "\n",
    "# 4. DataFrame으로 복원\n",
    "desc_imputed = pd.DataFrame(desc_imputed_array, columns=desc_numeric.columns)\n",
    "\n",
    "# 5. 이상치 클리핑\n",
    "desc_imputed = desc_imputed.clip(upper=1e6)\n",
    "\n",
    "# 6. X, y 준비\n",
    "X = desc_imputed\n",
    "y = df['Inhibition'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5cd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b902db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ridge(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "    model = make_pipeline(StandardScaler(), Ridge(alpha=alpha))\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def tune_lasso(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "    model = make_pipeline(StandardScaler(), Lasso(alpha=alpha, max_iter=10000))\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def tune_elasticnet(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "    model = make_pipeline(StandardScaler(), ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=10000))\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def tune_svr(trial):\n",
    "    C = trial.suggest_float(\"C\", 1e-2, 100.0, log=True)\n",
    "    epsilon = trial.suggest_float(\"epsilon\", 1e-3, 1.0, log=True)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"linear\"])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "    model = make_pipeline(StandardScaler(), SVR(C=C, epsilon=epsilon, kernel=kernel, gamma=gamma))\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def tune_rf(trial):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        max_features=trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def tune_gbr(trial):\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        random_state=42\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score\n",
    "\n",
    "def tune_histgbr(trial):\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_iter=trial.suggest_int(\"max_iter\", 50, 200),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        max_leaf_nodes=trial.suggest_int(\"max_leaf_nodes\", 10, 100),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        l2_regularization=trial.suggest_float(\"l2_regularization\", 0.0, 1.0),\n",
    "        random_state=42\n",
    "    )\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error').mean()\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf4ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 20:50:26,373] A new study created in memory with name: no-name-baefbef5-72e2-40ff-8b9f-1b0f902de2bd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tuning for Ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 20:50:26,801] Trial 0 finished with value: 74.55680384318372 and parameters: {'alpha': 0.0013122093042583797}. Best is trial 0 with value: 74.55680384318372.\n",
      "[I 2025-07-02 20:50:27,215] Trial 1 finished with value: 58.72197022315297 and parameters: {'alpha': 0.008546050552982675}. Best is trial 1 with value: 58.72197022315297.\n",
      "[I 2025-07-02 20:50:27,626] Trial 2 finished with value: 32.997808179422776 and parameters: {'alpha': 0.3180468202790417}. Best is trial 2 with value: 32.997808179422776.\n",
      "[I 2025-07-02 20:50:28,073] Trial 3 finished with value: 53.472666871248485 and parameters: {'alpha': 0.01456258229597984}. Best is trial 2 with value: 32.997808179422776.\n",
      "[I 2025-07-02 20:50:28,526] Trial 4 finished with value: 29.5361115397075 and parameters: {'alpha': 0.8563048445709946}. Best is trial 4 with value: 29.5361115397075.\n",
      "[I 2025-07-02 20:50:28,952] Trial 5 finished with value: 46.12170947923299 and parameters: {'alpha': 0.03337265266781515}. Best is trial 4 with value: 29.5361115397075.\n",
      "[I 2025-07-02 20:50:29,406] Trial 6 finished with value: 75.44241222953798 and parameters: {'alpha': 0.0011295535742821285}. Best is trial 4 with value: 29.5361115397075.\n",
      "[I 2025-07-02 20:50:29,860] Trial 7 finished with value: 34.41801870189921 and parameters: {'alpha': 0.2301088754091654}. Best is trial 4 with value: 29.5361115397075.\n",
      "[I 2025-07-02 20:50:30,308] Trial 8 finished with value: 27.97070915269262 and parameters: {'alpha': 1.6384277338475388}. Best is trial 8 with value: 27.97070915269262.\n",
      "[I 2025-07-02 20:50:30,720] Trial 9 finished with value: 27.666245610936993 and parameters: {'alpha': 1.9110852607931712}. Best is trial 9 with value: 27.666245610936993.\n",
      "[I 2025-07-02 20:50:31,178] Trial 10 finished with value: 25.559749205162067 and parameters: {'alpha': 8.64951836669923}. Best is trial 10 with value: 25.559749205162067.\n",
      "[I 2025-07-02 20:50:31,619] Trial 11 finished with value: 25.51779515640864 and parameters: {'alpha': 9.022477675788442}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:32,044] Trial 12 finished with value: 25.664531661543997 and parameters: {'alpha': 7.808107079901553}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:32,485] Trial 13 finished with value: 25.575145554701788 and parameters: {'alpha': 8.518101939656592}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:32,894] Trial 14 finished with value: 26.626251290795313 and parameters: {'alpha': 3.5773061661529364}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:33,335] Trial 15 finished with value: 31.139687864194105 and parameters: {'alpha': 0.5154199633445803}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:33,760] Trial 16 finished with value: 38.15193345665428 and parameters: {'alpha': 0.11022117219095062}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:34,202] Trial 17 finished with value: 26.498689833299828 and parameters: {'alpha': 3.9148754021257655}. Best is trial 11 with value: 25.51779515640864.\n",
      "[I 2025-07-02 20:50:34,628] Trial 18 finished with value: 25.442022960304865 and parameters: {'alpha': 9.755927280134099}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:35,069] Trial 19 finished with value: 28.937664301696792 and parameters: {'alpha': 1.0718849088894808}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:35,495] Trial 20 finished with value: 26.874482357716175 and parameters: {'alpha': 3.029632436081085}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:35,921] Trial 21 finished with value: 25.765624034484894 and parameters: {'alpha': 7.101733637640376}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:36,333] Trial 22 finished with value: 25.568857363983625 and parameters: {'alpha': 8.571432397299622}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:36,760] Trial 23 finished with value: 26.623470309241707 and parameters: {'alpha': 3.584216488032132}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:37,187] Trial 24 finished with value: 27.9423652990635 and parameters: {'alpha': 1.661297007019555}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:37,616] Trial 25 finished with value: 30.20016450003599 and parameters: {'alpha': 0.6843357073292674}. Best is trial 18 with value: 25.442022960304865.\n",
      "[I 2025-07-02 20:50:38,016] Trial 26 finished with value: 25.420527402336198 and parameters: {'alpha': 9.979305127179291}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:38,439] Trial 27 finished with value: 26.39873300396162 and parameters: {'alpha': 4.211831073087866}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:38,866] Trial 28 finished with value: 36.39041829678105 and parameters: {'alpha': 0.15328286313763445}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:39,292] Trial 29 finished with value: 41.98838364972939 and parameters: {'alpha': 0.058758769568676955}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:39,719] Trial 30 finished with value: 66.83537767663321 and parameters: {'alpha': 0.0036556998957219416}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:40,131] Trial 31 finished with value: 26.175077399836766 and parameters: {'alpha': 5.002659070757037}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:40,558] Trial 32 finished with value: 25.469634583887498 and parameters: {'alpha': 9.47922168420021}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:40,969] Trial 33 finished with value: 27.52208107778899 and parameters: {'alpha': 2.0640402908894138}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:41,396] Trial 34 finished with value: 25.428102927062685 and parameters: {'alpha': 9.899764825446407}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:41,807] Trial 35 finished with value: 26.23243117443237 and parameters: {'alpha': 4.781091662324211}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:42,225] Trial 36 finished with value: 28.75048020137988 and parameters: {'alpha': 1.1560154382277035}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:42,631] Trial 37 finished with value: 31.82073765290504 and parameters: {'alpha': 0.4275727711136211}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:43,073] Trial 38 finished with value: 57.24267804492858 and parameters: {'alpha': 0.009916650377351736}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:43,485] Trial 39 finished with value: 27.23586725785534 and parameters: {'alpha': 2.425822085292318}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:43,928] Trial 40 finished with value: 71.09394153071358 and parameters: {'alpha': 0.0021792026032152302}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:44,355] Trial 41 finished with value: 26.16833103227494 and parameters: {'alpha': 5.029667751941628}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:44,767] Trial 42 finished with value: 25.457833757023753 and parameters: {'alpha': 9.59610755048797}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:45,193] Trial 43 finished with value: 25.430337210485828 and parameters: {'alpha': 9.876476705529736}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:45,630] Trial 44 finished with value: 25.94656660030998 and parameters: {'alpha': 6.045362933679041}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:46,047] Trial 45 finished with value: 25.96377674562233 and parameters: {'alpha': 5.9566693928872985}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:46,459] Trial 46 finished with value: 47.48534216959324 and parameters: {'alpha': 0.02823478148911175}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:46,887] Trial 47 finished with value: 27.01492926067747 and parameters: {'alpha': 2.771666675448021}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:47,314] Trial 48 finished with value: 28.76443911963737 and parameters: {'alpha': 1.149408090209061}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:47,727] Trial 49 finished with value: 25.423483522157067 and parameters: {'alpha': 9.948159880539835}. Best is trial 26 with value: 25.420527402336198.\n",
      "[I 2025-07-02 20:50:47,727] A new study created in memory with name: no-name-0291a683-04af-4139-9ed1-a1d48146fe3f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge done. Best RMSE: 25.4205\n",
      "Starting tuning for Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.796e+03, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.273e+03, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.649e+03, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:51:02,818] Trial 0 finished with value: 27.81941704196542 and parameters: {'alpha': 0.011878176336633421}. Best is trial 0 with value: 27.81941704196542.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+04, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.581e+04, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.728e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.933e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:51:19,129] Trial 1 finished with value: 29.69550645968743 and parameters: {'alpha': 0.0066485505611132804}. Best is trial 0 with value: 27.81941704196542.\n",
      "[I 2025-07-02 20:51:21,507] Trial 2 finished with value: 24.104110672078864 and parameters: {'alpha': 0.08967779268246127}. Best is trial 2 with value: 24.104110672078864.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+03, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.864e+01, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+02, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.324e+02, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:51:35,810] Trial 3 finished with value: 25.644294758101456 and parameters: {'alpha': 0.029045247113502627}. Best is trial 2 with value: 24.104110672078864.\n",
      "[I 2025-07-02 20:51:36,159] Trial 4 finished with value: 23.762159321174835 and parameters: {'alpha': 0.8368409075036174}. Best is trial 4 with value: 23.762159321174835.\n",
      "[I 2025-07-02 20:51:36,429] Trial 5 finished with value: 24.03388767191368 and parameters: {'alpha': 1.5730780772440511}. Best is trial 4 with value: 23.762159321174835.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+05, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+05, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+05, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+05, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+05, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:51:55,530] Trial 6 finished with value: 38.009973450442125 and parameters: {'alpha': 0.0010462421676780242}. Best is trial 4 with value: 23.762159321174835.\n",
      "[I 2025-07-02 20:51:56,569] Trial 7 finished with value: 23.708237273558204 and parameters: {'alpha': 0.260438811930775}. Best is trial 7 with value: 23.708237273558204.\n",
      "[I 2025-07-02 20:51:56,971] Trial 8 finished with value: 23.71461918014643 and parameters: {'alpha': 0.7209168279838086}. Best is trial 7 with value: 23.708237273558204.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.504e+02, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+03, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.513e+02, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.154e+02, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:52:10,906] Trial 9 finished with value: 26.241378954536817 and parameters: {'alpha': 0.022089781028471485}. Best is trial 7 with value: 23.708237273558204.\n",
      "[I 2025-07-02 20:52:11,098] Trial 10 finished with value: 25.101006114688044 and parameters: {'alpha': 5.045008105059942}. Best is trial 7 with value: 23.708237273558204.\n",
      "[I 2025-07-02 20:52:11,871] Trial 11 finished with value: 23.661224371020815 and parameters: {'alpha': 0.4790879163663803}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:13,087] Trial 12 finished with value: 23.7918233007311 and parameters: {'alpha': 0.19361540204594893}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:14,289] Trial 13 finished with value: 23.78471527540063 and parameters: {'alpha': 0.1988176936393657}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:14,495] Trial 14 finished with value: 25.577023781495857 and parameters: {'alpha': 6.526885271716565}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:17,232] Trial 15 finished with value: 24.167101172304736 and parameters: {'alpha': 0.07848613302041706}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:17,849] Trial 16 finished with value: 23.669467396364773 and parameters: {'alpha': 0.548923319138762}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:18,150] Trial 17 finished with value: 24.10255537421246 and parameters: {'alpha': 1.8394106433241533}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:18,655] Trial 18 finished with value: 23.72022059480698 and parameters: {'alpha': 0.7368443192497337}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:18,876] Trial 19 finished with value: 24.606808797064495 and parameters: {'alpha': 3.357139045120816}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:19,888] Trial 20 finished with value: 23.675680794761274 and parameters: {'alpha': 0.3472422556462625}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:20,776] Trial 21 finished with value: 23.66266395805519 and parameters: {'alpha': 0.3787254654972484}. Best is trial 11 with value: 23.661224371020815.\n",
      "[I 2025-07-02 20:52:21,551] Trial 22 finished with value: 23.656269353402223 and parameters: {'alpha': 0.44703857706490563}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:25,080] Trial 23 finished with value: 24.271990508354776 and parameters: {'alpha': 0.06756226563265409}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:25,364] Trial 24 finished with value: 24.159525120052216 and parameters: {'alpha': 2.0114182164575065}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:26,583] Trial 25 finished with value: 23.81307551547844 and parameters: {'alpha': 0.17938616938381674}. Best is trial 22 with value: 23.656269353402223.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.234e+02, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.524e+02, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:52:36,178] Trial 26 finished with value: 24.905582764756073 and parameters: {'alpha': 0.04093195884956738}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:36,969] Trial 27 finished with value: 23.657535634776117 and parameters: {'alpha': 0.39531065851459574}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:37,285] Trial 28 finished with value: 23.87149228159702 and parameters: {'alpha': 1.0623617327220636}. Best is trial 22 with value: 23.656269353402223.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+04, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.585e+04, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.904e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:52:51,808] Trial 29 finished with value: 28.747772894685273 and parameters: {'alpha': 0.008150273651765752}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:52,015] Trial 30 finished with value: 26.39922142435419 and parameters: {'alpha': 9.681224659613848}. Best is trial 22 with value: 23.656269353402223.\n",
      "[I 2025-07-02 20:52:52,887] Trial 31 finished with value: 23.654404885276325 and parameters: {'alpha': 0.4372903504031835}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:52:53,598] Trial 32 finished with value: 23.65895548308261 and parameters: {'alpha': 0.4594118159217863}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:52:55,045] Trial 33 finished with value: 23.841407315762417 and parameters: {'alpha': 0.16129643800629329}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:52:56,427] Trial 34 finished with value: 23.915906312701026 and parameters: {'alpha': 0.13036760471662842}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:52:56,713] Trial 35 finished with value: 23.94802716480134 and parameters: {'alpha': 1.2659951199907062}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:52:56,952] Trial 36 finished with value: 24.458645727583036 and parameters: {'alpha': 2.8092428210603417}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:52:58,127] Trial 37 finished with value: 23.688701710203752 and parameters: {'alpha': 0.3082459763422778}. Best is trial 31 with value: 23.654404885276325.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.935e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.910e+04, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.921e+04, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.214e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.259e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:53:14,123] Trial 38 finished with value: 34.5528970614647 and parameters: {'alpha': 0.002642494878568785}. Best is trial 31 with value: 23.654404885276325.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+02, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.960e+02, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:53:24,319] Trial 39 finished with value: 24.745938342255233 and parameters: {'alpha': 0.045251143213520376}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:26,238] Trial 40 finished with value: 24.036297259809103 and parameters: {'alpha': 0.10290012607979854}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:27,093] Trial 41 finished with value: 23.666422974790027 and parameters: {'alpha': 0.3690874234350825}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:27,725] Trial 42 finished with value: 23.666392611894818 and parameters: {'alpha': 0.5235274096828337}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:28,169] Trial 43 finished with value: 23.68865904333467 and parameters: {'alpha': 0.6325697741871722}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:28,527] Trial 44 finished with value: 23.85723407898463 and parameters: {'alpha': 1.0360762797131147}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:29,260] Trial 45 finished with value: 23.665727222002147 and parameters: {'alpha': 0.5150012807617736}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:30,194] Trial 46 finished with value: 23.741289168102107 and parameters: {'alpha': 0.2322417089080919}. Best is trial 31 with value: 23.654404885276325.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+03, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+03, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.014e+02, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+02, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:53:44,661] Trial 47 finished with value: 26.568971780663237 and parameters: {'alpha': 0.01951918024217485}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:44,943] Trial 48 finished with value: 24.008497975124993 and parameters: {'alpha': 1.4667907135585767}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:45,325] Trial 49 finished with value: 23.7758083144648 and parameters: {'alpha': 0.8634522708912605}. Best is trial 31 with value: 23.654404885276325.\n",
      "[I 2025-07-02 20:53:45,325] A new study created in memory with name: no-name-f7567576-8141-4e61-bac8-beccfeb7807d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso done. Best RMSE: 23.6544\n",
      "Starting tuning for ElasticNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+05, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+05, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+05, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+05, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+05, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:54:04,737] Trial 0 finished with value: 26.516621385183942 and parameters: {'alpha': 0.0030986588369041773, 'l1_ratio': 0.08172136096363891}. Best is trial 0 with value: 26.516621385183942.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.443e+03, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+03, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e+03, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.975e+03, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:54:19,791] Trial 1 finished with value: 24.82108615578584 and parameters: {'alpha': 0.021714114271931123, 'l1_ratio': 0.5906628319056934}. Best is trial 1 with value: 24.82108615578584.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.542e+03, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.102e+03, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e+03, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.834e+03, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.872e+03, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:54:34,615] Trial 2 finished with value: 25.874554613717216 and parameters: {'alpha': 0.014936332844264313, 'l1_ratio': 0.8800913261433598}. Best is trial 1 with value: 24.82108615578584.\n",
      "[I 2025-07-02 20:54:34,808] Trial 3 finished with value: 26.047845518092515 and parameters: {'alpha': 8.721983204000356, 'l1_ratio': 0.8338541322959956}. Best is trial 1 with value: 24.82108615578584.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.527e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.711e+04, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.535e+04, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.506e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:54:51,538] Trial 4 finished with value: 24.21948397192121 and parameters: {'alpha': 0.04521552802742751, 'l1_ratio': 0.11712621261744949}. Best is trial 4 with value: 24.21948397192121.\n",
      "[I 2025-07-02 20:54:52,266] Trial 5 finished with value: 23.686439699575764 and parameters: {'alpha': 0.2740018192617736, 'l1_ratio': 0.8634532872888606}. Best is trial 5 with value: 23.686439699575764.\n",
      "[I 2025-07-02 20:54:52,472] Trial 6 finished with value: 25.369885968896245 and parameters: {'alpha': 6.843416067994731, 'l1_ratio': 0.7047520928431928}. Best is trial 5 with value: 23.686439699575764.\n",
      "[I 2025-07-02 20:54:58,893] Trial 7 finished with value: 24.02934341805119 and parameters: {'alpha': 0.07495055987612866, 'l1_ratio': 0.687819133082146}. Best is trial 5 with value: 23.686439699575764.\n",
      "[I 2025-07-02 20:55:00,164] Trial 8 finished with value: 23.71105392473705 and parameters: {'alpha': 0.20994359937361784, 'l1_ratio': 0.640487197811356}. Best is trial 5 with value: 23.686439699575764.\n",
      "[I 2025-07-02 20:55:00,911] Trial 9 finished with value: 23.703010977225155 and parameters: {'alpha': 0.24793966682282162, 'l1_ratio': 0.8738402602876116}. Best is trial 5 with value: 23.686439699575764.\n",
      "[I 2025-07-02 20:55:01,340] Trial 10 finished with value: 23.744067466637556 and parameters: {'alpha': 1.5169591808318574, 'l1_ratio': 0.3437267317523866}. Best is trial 5 with value: 23.686439699575764.\n",
      "[I 2025-07-02 20:55:01,800] Trial 11 finished with value: 23.657052542619283 and parameters: {'alpha': 0.3558254266802167, 'l1_ratio': 0.9473044717414161}. Best is trial 11 with value: 23.657052542619283.\n",
      "[I 2025-07-02 20:55:02,324] Trial 12 finished with value: 23.80356929808489 and parameters: {'alpha': 0.921902710145358, 'l1_ratio': 0.9988583402538569}. Best is trial 11 with value: 23.657052542619283.\n",
      "[I 2025-07-02 20:55:02,929] Trial 13 finished with value: 23.615300752347544 and parameters: {'alpha': 0.6890380542361974, 'l1_ratio': 0.40735723313109307}. Best is trial 13 with value: 23.615300752347544.\n",
      "[I 2025-07-02 20:55:03,327] Trial 14 finished with value: 23.734121475515174 and parameters: {'alpha': 1.338692915207808, 'l1_ratio': 0.40091366093657266}. Best is trial 13 with value: 23.615300752347544.\n",
      "[I 2025-07-02 20:55:04,162] Trial 15 finished with value: 23.596710735101787 and parameters: {'alpha': 0.6739806397670329, 'l1_ratio': 0.2974690290985006}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:04,521] Trial 16 finished with value: 23.90043708609075 and parameters: {'alpha': 2.7870556112571316, 'l1_ratio': 0.23046427095309374}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:05,064] Trial 17 finished with value: 23.61650909940641 and parameters: {'alpha': 0.6506570805155607, 'l1_ratio': 0.4307702587506286}. Best is trial 15 with value: 23.596710735101787.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e+05, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+05, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+05, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+05, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+05, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:55:23,968] Trial 18 finished with value: 28.976135189437947 and parameters: {'alpha': 0.0010827380713357166, 'l1_ratio': 0.2586929428514949}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:24,205] Trial 19 finished with value: 24.517472424972347 and parameters: {'alpha': 4.2048157141238445, 'l1_ratio': 0.5179521355572874}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:35,914] Trial 20 finished with value: 23.84165985546253 and parameters: {'alpha': 0.1286739069942943, 'l1_ratio': 0.19014092117057968}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:36,642] Trial 21 finished with value: 23.606551608395478 and parameters: {'alpha': 0.5899064026819267, 'l1_ratio': 0.3989718887865405}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:37,438] Trial 22 finished with value: 23.602335980141515 and parameters: {'alpha': 0.5417054555560444, 'l1_ratio': 0.33593774159662954}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:37,799] Trial 23 finished with value: 23.96515192909684 and parameters: {'alpha': 2.5861177938895694, 'l1_ratio': 0.3161297029295019}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:38,424] Trial 24 finished with value: 23.62167661466657 and parameters: {'alpha': 0.500125833474707, 'l1_ratio': 0.5054767698385332}. Best is trial 15 with value: 23.596710735101787.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+05, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+05, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+05, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+05, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+05, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:55:54,760] Trial 25 finished with value: 23.983559656074597 and parameters: {'alpha': 0.08411460000137347, 'l1_ratio': 0.03013314167340836}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:55:55,441] Trial 26 finished with value: 23.632643889108923 and parameters: {'alpha': 1.493828044270902, 'l1_ratio': 0.15162624336500544}. Best is trial 15 with value: 23.596710735101787.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.930e+03, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.771e+03, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.287e+03, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:56:12,330] Trial 27 finished with value: 24.288738265537212 and parameters: {'alpha': 0.039686139309160054, 'l1_ratio': 0.2684948649315754}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:16,936] Trial 28 finished with value: 23.76617491515425 and parameters: {'alpha': 0.15973842552444104, 'l1_ratio': 0.3376292141808781}. Best is trial 15 with value: 23.596710735101787.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e+04, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.835e+04, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.664e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.298e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:56:31,400] Trial 29 finished with value: 25.21384381016615 and parameters: {'alpha': 0.012700929724688979, 'l1_ratio': 0.4580887525973202}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:39,004] Trial 30 finished with value: 23.64707093101386 and parameters: {'alpha': 0.44378746456023016, 'l1_ratio': 0.04660413508872108}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:39,589] Trial 31 finished with value: 23.622170904493593 and parameters: {'alpha': 0.789760112711413, 'l1_ratio': 0.3936730275568017}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:39,858] Trial 32 finished with value: 24.154644309137133 and parameters: {'alpha': 2.6410961450258768, 'l1_ratio': 0.49780885176048006}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:40,287] Trial 33 finished with value: 23.699180390333574 and parameters: {'alpha': 0.9524063585413074, 'l1_ratio': 0.5678397771938493}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:41,394] Trial 34 finished with value: 23.611485117384063 and parameters: {'alpha': 0.47649364898612323, 'l1_ratio': 0.30261502513377714}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:56:42,517] Trial 35 finished with value: 23.6199788123391 and parameters: {'alpha': 0.4334231172174769, 'l1_ratio': 0.29958223805442064}. Best is trial 15 with value: 23.596710735101787.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+05, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+05, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+05, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+05, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+05, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:56:59,678] Trial 36 finished with value: 25.46708074515534 and parameters: {'alpha': 0.008035653289016375, 'l1_ratio': 0.19958893645008405}. Best is trial 15 with value: 23.596710735101787.\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.269e+04, tolerance: 9.370e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.742e+04, tolerance: 9.544e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.413e+04, tolerance: 9.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.732e+04, tolerance: 9.519e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sbjan\\miniconda3\\envs\\scikit_test\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.602e+04, tolerance: 9.186e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-07-02 20:57:16,182] Trial 37 finished with value: 24.169548400447134 and parameters: {'alpha': 0.05053050266324895, 'l1_ratio': 0.10632204115867916}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:16,420] Trial 38 finished with value: 24.48671877147084 and parameters: {'alpha': 5.184704174127449, 'l1_ratio': 0.33714127832678303}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:19,740] Trial 39 finished with value: 23.75696376976731 and parameters: {'alpha': 0.1642155349911814, 'l1_ratio': 0.3709301373693995}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:20,627] Trial 40 finished with value: 23.658575453010723 and parameters: {'alpha': 0.2989088118939623, 'l1_ratio': 0.5929625950167592}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:21,212] Trial 41 finished with value: 23.618676677702584 and parameters: {'alpha': 0.6399137983661396, 'l1_ratio': 0.44836871426725955}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:21,624] Trial 42 finished with value: 23.75000604979864 and parameters: {'alpha': 1.7324568103462394, 'l1_ratio': 0.2836258112816198}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:26,881] Trial 43 finished with value: 23.704017687505694 and parameters: {'alpha': 0.25923500801216914, 'l1_ratio': 0.15764967799545446}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:27,355] Trial 44 finished with value: 23.65283183625251 and parameters: {'alpha': 0.9957619812699235, 'l1_ratio': 0.38930834747884707}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:28,257] Trial 45 finished with value: 23.600599374899225 and parameters: {'alpha': 0.6082398575282498, 'l1_ratio': 0.23898255454473105}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:40,284] Trial 46 finished with value: 23.89511338175607 and parameters: {'alpha': 0.10597107166577449, 'l1_ratio': 0.2151478384898049}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:44,734] Trial 47 finished with value: 23.74479083820421 and parameters: {'alpha': 0.188412121604088, 'l1_ratio': 0.2521703273981013}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:49,074] Trial 48 finished with value: 23.682133430936453 and parameters: {'alpha': 0.30105871465173956, 'l1_ratio': 0.1457118604168683}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:49,407] Trial 49 finished with value: 23.885988308426032 and parameters: {'alpha': 2.065403242136904, 'l1_ratio': 0.35954457372996995}. Best is trial 15 with value: 23.596710735101787.\n",
      "[I 2025-07-02 20:57:49,407] A new study created in memory with name: no-name-43c53ba7-9c8f-4f5f-9f52-fcf5f6fa99f7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet done. Best RMSE: 23.5967\n",
      "Starting tuning for SVR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 20:57:51,645] Trial 0 finished with value: 24.547165725677623 and parameters: {'C': 0.161207045593066, 'epsilon': 0.007890953606500276, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 24.547165725677623.\n",
      "[I 2025-07-02 21:03:35,877] Trial 1 finished with value: 33.41532926867329 and parameters: {'C': 33.09432968851386, 'epsilon': 0.08309452529956919, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 24.547165725677623.\n",
      "[I 2025-07-02 21:03:42,129] Trial 2 finished with value: 26.039139378377694 and parameters: {'C': 1.0068118014063043, 'epsilon': 0.026104274543906757, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 24.547165725677623.\n",
      "[I 2025-07-02 21:03:44,318] Trial 3 finished with value: 24.58876396860878 and parameters: {'C': 58.16792047190151, 'epsilon': 0.007280054236916293, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 24.547165725677623.\n",
      "[I 2025-07-02 21:03:46,366] Trial 4 finished with value: 24.406496923618214 and parameters: {'C': 0.07933934668846285, 'epsilon': 0.0031190795608336797, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 4 with value: 24.406496923618214.\n",
      "[I 2025-07-02 21:16:15,570] Trial 5 finished with value: 34.597129637155476 and parameters: {'C': 54.295330076711906, 'epsilon': 0.004657635560707639, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 4 with value: 24.406496923618214.\n",
      "[I 2025-07-02 21:16:17,577] Trial 6 finished with value: 24.161997041897592 and parameters: {'C': 14.123211944011496, 'epsilon': 0.0013067594109705844, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 24.161997041897592.\n",
      "[I 2025-07-02 21:16:19,665] Trial 7 finished with value: 24.795261796219215 and parameters: {'C': 1.9409445446759812, 'epsilon': 0.004333407362122061, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 24.161997041897592.\n",
      "[I 2025-07-02 21:19:06,906] Trial 8 finished with value: 31.151852755244853 and parameters: {'C': 16.206554046689266, 'epsilon': 0.00919309793068091, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 6 with value: 24.161997041897592.\n",
      "[I 2025-07-02 21:19:09,201] Trial 9 finished with value: 24.3463922995281 and parameters: {'C': 4.844883817530411, 'epsilon': 0.04963191885025302, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 24.161997041897592.\n",
      "[I 2025-07-02 21:19:11,496] Trial 10 finished with value: 26.699900615135174 and parameters: {'C': 0.010018778983806206, 'epsilon': 0.627505734864151, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 24.161997041897592.\n",
      "[I 2025-07-02 21:19:13,868] Trial 11 finished with value: 24.157220977470114 and parameters: {'C': 10.120958969784997, 'epsilon': 0.1265209844283531, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 24.157220977470114.\n",
      "[I 2025-07-02 21:19:16,180] Trial 12 finished with value: 24.253292136198194 and parameters: {'C': 6.324008927732191, 'epsilon': 0.20072942131535412, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 24.157220977470114.\n",
      "[I 2025-07-02 21:19:18,271] Trial 13 finished with value: 24.155229469458302 and parameters: {'C': 10.79325799039535, 'epsilon': 0.23180914472894745, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:20,422] Trial 14 finished with value: 25.854211229456098 and parameters: {'C': 0.32657340910783866, 'epsilon': 0.8696926676486911, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:22,506] Trial 15 finished with value: 24.476023594693707 and parameters: {'C': 3.7242586794664776, 'epsilon': 0.27634946983180625, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:24,766] Trial 16 finished with value: 24.169870986526117 and parameters: {'C': 17.692819404291942, 'epsilon': 0.14976864796670708, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:26,787] Trial 17 finished with value: 25.423396459220914 and parameters: {'C': 0.6731047152407299, 'epsilon': 0.027349380557025207, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:29,107] Trial 18 finished with value: 24.914233637475473 and parameters: {'C': 85.10653512572756, 'epsilon': 0.2945621608799968, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:31,222] Trial 19 finished with value: 24.165875332955263 and parameters: {'C': 9.405004145020612, 'epsilon': 0.08507619154368626, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:33,242] Trial 20 finished with value: 24.906120129662224 and parameters: {'C': 1.6185997409503856, 'epsilon': 0.45978276344484803, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:35,570] Trial 21 finished with value: 24.186801519386897 and parameters: {'C': 20.65037514314835, 'epsilon': 0.001175970155862103, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:37,824] Trial 22 finished with value: 24.15856831297968 and parameters: {'C': 9.99871269091374, 'epsilon': 0.09292976040659315, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:39,954] Trial 23 finished with value: 24.68384219728787 and parameters: {'C': 2.3900960032465637, 'epsilon': 0.11348553692059285, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:42,054] Trial 24 finished with value: 24.191900598751463 and parameters: {'C': 7.955917946342678, 'epsilon': 0.04958374043297338, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:44,119] Trial 25 finished with value: 24.445802410136498 and parameters: {'C': 42.18657300871221, 'epsilon': 0.046097209889368315, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:46,124] Trial 26 finished with value: 24.4397797913364 and parameters: {'C': 3.697542201603923, 'epsilon': 0.01911360454839981, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:48,146] Trial 27 finished with value: 24.20011590011061 and parameters: {'C': 24.29661749092468, 'epsilon': 0.31051358418695685, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:50,518] Trial 28 finished with value: 24.15820454719891 and parameters: {'C': 9.959698821414731, 'epsilon': 0.15477777123192735, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:52,556] Trial 29 finished with value: 24.3933508234718 and parameters: {'C': 0.0794293309465285, 'epsilon': 0.1729741598104154, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:55,300] Trial 30 finished with value: 25.022642964633594 and parameters: {'C': 98.66451308156518, 'epsilon': 0.4640300685896398, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:57,619] Trial 31 finished with value: 24.15777126235285 and parameters: {'C': 10.088679821223385, 'epsilon': 0.09310568614564972, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:19:59,814] Trial 32 finished with value: 24.23636471875772 and parameters: {'C': 27.261620891575518, 'epsilon': 0.1337076323703114, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:20:01,966] Trial 33 finished with value: 25.42869048850943 and parameters: {'C': 0.6646014571249214, 'epsilon': 0.057880577511465955, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:20:22,334] Trial 34 finished with value: 27.769549777363693 and parameters: {'C': 3.1494889689142416, 'epsilon': 0.22697710380438252, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:20:24,440] Trial 35 finished with value: 24.27248370294319 and parameters: {'C': 5.947822518646029, 'epsilon': 0.45152338045616536, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:20:32,643] Trial 36 finished with value: 26.396720462294034 and parameters: {'C': 1.2491154592677305, 'epsilon': 0.015230923227044495, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:20:34,809] Trial 37 finished with value: 24.156452753923627 and parameters: {'C': 10.326388177255586, 'epsilon': 0.08163599295526491, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:20:37,321] Trial 38 finished with value: 24.29259123065976 and parameters: {'C': 31.069553076176934, 'epsilon': 0.03316501454070099, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:39,555] Trial 39 finished with value: 30.9570665403215 and parameters: {'C': 13.769683138521762, 'epsilon': 0.06434925657901792, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:41,803] Trial 40 finished with value: 24.673793983985924 and parameters: {'C': 60.28713029644487, 'epsilon': 0.07687046862558108, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:43,878] Trial 41 finished with value: 24.15568091112013 and parameters: {'C': 10.534131652317388, 'epsilon': 0.10445101018179467, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:45,922] Trial 42 finished with value: 24.158621483881955 and parameters: {'C': 12.36668516097399, 'epsilon': 0.11044444716041665, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:47,997] Trial 43 finished with value: 24.278522091410633 and parameters: {'C': 5.824241159647446, 'epsilon': 0.03702015980066611, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:50,452] Trial 44 finished with value: 24.67146636725202 and parameters: {'C': 2.4475687523736083, 'epsilon': 0.07995822530417389, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:52,679] Trial 45 finished with value: 24.33737141734106 and parameters: {'C': 34.63227246851789, 'epsilon': 0.21165167659688136, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:55,014] Trial 46 finished with value: 24.432227429564193 and parameters: {'C': 4.072725740667991, 'epsilon': 0.019971547238975967, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 13 with value: 24.155229469458302.\n",
      "[I 2025-07-02 21:22:56,907] Trial 47 finished with value: 24.084095208575455 and parameters: {'C': 0.011716986553713244, 'epsilon': 0.12598692936482805, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 47 with value: 24.084095208575455.\n",
      "[I 2025-07-02 21:22:58,738] Trial 48 finished with value: 24.30784824666666 and parameters: {'C': 0.03473460313639616, 'epsilon': 0.347129540190681, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 47 with value: 24.084095208575455.\n",
      "[I 2025-07-02 21:23:00,886] Trial 49 finished with value: 24.599091491936054 and parameters: {'C': 0.18006068875719633, 'epsilon': 0.12632218046157043, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 47 with value: 24.084095208575455.\n",
      "[I 2025-07-02 21:23:00,886] A new study created in memory with name: no-name-96f6bce5-3d71-4809-b519-0282836fa16a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR done. Best RMSE: 24.0841\n",
      "Starting tuning for RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 21:23:01,741] Trial 0 finished with value: 24.378158251673575 and parameters: {'n_estimators': 123, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 24.378158251673575.\n",
      "[I 2025-07-02 21:23:03,260] Trial 1 finished with value: 24.26554911116299 and parameters: {'n_estimators': 198, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:04,115] Trial 2 finished with value: 24.55720532057412 and parameters: {'n_estimators': 142, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:05,033] Trial 3 finished with value: 24.291639494093896 and parameters: {'n_estimators': 116, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:06,203] Trial 4 finished with value: 24.380116163907804 and parameters: {'n_estimators': 185, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:07,139] Trial 5 finished with value: 24.317186127065238 and parameters: {'n_estimators': 101, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:08,167] Trial 6 finished with value: 24.382653484636297 and parameters: {'n_estimators': 158, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:09,023] Trial 7 finished with value: 24.3737850566636 and parameters: {'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 1 with value: 24.26554911116299.\n",
      "[I 2025-07-02 21:23:09,880] Trial 8 finished with value: 24.158303453310847 and parameters: {'n_estimators': 97, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:10,623] Trial 9 finished with value: 24.6865689907022 and parameters: {'n_estimators': 132, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:11,256] Trial 10 finished with value: 24.3301395983921 and parameters: {'n_estimators': 52, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:12,648] Trial 11 finished with value: 24.168252137816957 and parameters: {'n_estimators': 199, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:13,454] Trial 12 finished with value: 24.1628878279445 and parameters: {'n_estimators': 95, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:14,248] Trial 13 finished with value: 24.19009296599723 and parameters: {'n_estimators': 84, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:15,055] Trial 14 finished with value: 24.233135932985927 and parameters: {'n_estimators': 90, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:15,819] Trial 15 finished with value: 24.22588637692588 and parameters: {'n_estimators': 77, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:16,659] Trial 16 finished with value: 24.27719144722554 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:17,564] Trial 17 finished with value: 24.2313001883034 and parameters: {'n_estimators': 112, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:18,751] Trial 18 finished with value: 24.21411871244956 and parameters: {'n_estimators': 155, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:19,451] Trial 19 finished with value: 24.443818953122886 and parameters: {'n_estimators': 58, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:20,181] Trial 20 finished with value: 24.273393637627244 and parameters: {'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:21,495] Trial 21 finished with value: 24.165958859987146 and parameters: {'n_estimators': 172, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:22,779] Trial 22 finished with value: 24.16323929931708 and parameters: {'n_estimators': 173, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:23,649] Trial 23 finished with value: 24.23832392573938 and parameters: {'n_estimators': 103, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:24,759] Trial 24 finished with value: 24.21008445951982 and parameters: {'n_estimators': 140, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:25,566] Trial 25 finished with value: 24.27064942596404 and parameters: {'n_estimators': 93, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:26,594] Trial 26 finished with value: 24.3999103791565 and parameters: {'n_estimators': 157, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:27,860] Trial 27 finished with value: 24.24694449698586 and parameters: {'n_estimators': 171, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:28,762] Trial 28 finished with value: 24.250280924392744 and parameters: {'n_estimators': 114, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:29,598] Trial 29 finished with value: 24.350569506473107 and parameters: {'n_estimators': 122, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:30,548] Trial 30 finished with value: 24.29836109480099 and parameters: {'n_estimators': 131, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:31,845] Trial 31 finished with value: 24.161455338816744 and parameters: {'n_estimators': 176, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:33,172] Trial 32 finished with value: 24.18356825982819 and parameters: {'n_estimators': 181, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:34,502] Trial 33 finished with value: 24.288142512631932 and parameters: {'n_estimators': 188, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:35,735] Trial 34 finished with value: 24.223633910149385 and parameters: {'n_estimators': 171, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:36,952] Trial 35 finished with value: 24.164625549379135 and parameters: {'n_estimators': 152, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:38,091] Trial 36 finished with value: 24.35442027620091 and parameters: {'n_estimators': 189, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:39,183] Trial 37 finished with value: 24.2856815358273 and parameters: {'n_estimators': 146, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:40,592] Trial 38 finished with value: 24.201479616125606 and parameters: {'n_estimators': 164, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:41,351] Trial 39 finished with value: 24.36402740617379 and parameters: {'n_estimators': 96, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:42,252] Trial 40 finished with value: 24.241419550956685 and parameters: {'n_estimators': 107, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:43,598] Trial 41 finished with value: 24.19239999384236 and parameters: {'n_estimators': 180, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:44,785] Trial 42 finished with value: 24.292083782633643 and parameters: {'n_estimators': 150, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:46,015] Trial 43 finished with value: 24.212746124450977 and parameters: {'n_estimators': 165, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:47,437] Trial 44 finished with value: 24.235015933592628 and parameters: {'n_estimators': 192, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:48,506] Trial 45 finished with value: 24.28079607949004 and parameters: {'n_estimators': 136, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:49,833] Trial 46 finished with value: 24.234402977657403 and parameters: {'n_estimators': 177, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:50,623] Trial 47 finished with value: 24.55596708037286 and parameters: {'n_estimators': 121, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:51,412] Trial 48 finished with value: 24.26667563804704 and parameters: {'n_estimators': 87, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:52,124] Trial 49 finished with value: 24.630802305869434 and parameters: {'n_estimators': 81, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 8 with value: 24.158303453310847.\n",
      "[I 2025-07-02 21:23:52,124] A new study created in memory with name: no-name-634e191a-0a5f-4401-b91b-f6e0ce48f095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest done. Best RMSE: 24.1583\n",
      "Starting tuning for GradientBoosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 21:26:23,308] Trial 0 finished with value: 26.28508429655875 and parameters: {'n_estimators': 96, 'learning_rate': 0.21967850436765998, 'max_depth': 7, 'subsample': 0.759925133949606}. Best is trial 0 with value: 26.28508429655875.\n",
      "[I 2025-07-02 21:27:27,353] Trial 1 finished with value: 25.001528181413175 and parameters: {'n_estimators': 67, 'learning_rate': 0.17265560150113168, 'max_depth': 4, 'subsample': 0.7659099382556606}. Best is trial 1 with value: 25.001528181413175.\n",
      "[I 2025-07-02 21:28:22,937] Trial 2 finished with value: 24.317193863867452 and parameters: {'n_estimators': 84, 'learning_rate': 0.07627068534048818, 'max_depth': 3, 'subsample': 0.6969510325529393}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:30:27,600] Trial 3 finished with value: 25.74985248060179 and parameters: {'n_estimators': 107, 'learning_rate': 0.22108690790185107, 'max_depth': 5, 'subsample': 0.7407483305253597}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:34:39,460] Trial 4 finished with value: 25.994274140991884 and parameters: {'n_estimators': 124, 'learning_rate': 0.29196147832134534, 'max_depth': 7, 'subsample': 0.9467459089745389}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:39:26,938] Trial 5 finished with value: 26.266141278936868 and parameters: {'n_estimators': 152, 'learning_rate': 0.22907267016069577, 'max_depth': 9, 'subsample': 0.713831872370706}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:41:21,754] Trial 6 finished with value: 25.259149761007574 and parameters: {'n_estimators': 119, 'learning_rate': 0.1776380375128824, 'max_depth': 4, 'subsample': 0.7923640511842154}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:42:41,197] Trial 7 finished with value: 25.73246455447965 and parameters: {'n_estimators': 63, 'learning_rate': 0.21628908033399874, 'max_depth': 5, 'subsample': 0.7974838033644563}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:46:10,141] Trial 8 finished with value: 25.086204412811334 and parameters: {'n_estimators': 105, 'learning_rate': 0.14730442398677926, 'max_depth': 7, 'subsample': 0.9341682344863285}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:47:16,254] Trial 9 finished with value: 25.371179887993193 and parameters: {'n_estimators': 119, 'learning_rate': 0.20972108946118254, 'max_depth': 3, 'subsample': 0.6030971686679167}. Best is trial 2 with value: 24.317193863867452.\n",
      "[I 2025-07-02 21:52:42,760] Trial 10 finished with value: 24.049716433620347 and parameters: {'n_estimators': 181, 'learning_rate': 0.02039400460891938, 'max_depth': 10, 'subsample': 0.6369638865672013}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 21:58:31,988] Trial 11 finished with value: 24.195968056076158 and parameters: {'n_estimators': 193, 'learning_rate': 0.026044933231260704, 'max_depth': 10, 'subsample': 0.6407135587372965}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:04:08,210] Trial 12 finished with value: 24.139618966440747 and parameters: {'n_estimators': 200, 'learning_rate': 0.015452752791992059, 'max_depth': 10, 'subsample': 0.6041060800150752}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:09:43,478] Trial 13 finished with value: 24.063357443075336 and parameters: {'n_estimators': 197, 'learning_rate': 0.016642210453844706, 'max_depth': 9, 'subsample': 0.6543554185723222}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:16:02,027] Trial 14 finished with value: 24.579284325347153 and parameters: {'n_estimators': 161, 'learning_rate': 0.07610275218497378, 'max_depth': 9, 'subsample': 0.8792915707616298}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:21:03,876] Trial 15 finished with value: 24.615946832754254 and parameters: {'n_estimators': 173, 'learning_rate': 0.06985602718037004, 'max_depth': 9, 'subsample': 0.6695063078645276}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:27:15,165] Trial 16 finished with value: 24.82681613820025 and parameters: {'n_estimators': 179, 'learning_rate': 0.10678607644549593, 'max_depth': 8, 'subsample': 0.868102894668052}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:31:53,056] Trial 17 finished with value: 24.403501106587093 and parameters: {'n_estimators': 150, 'learning_rate': 0.04290369722991356, 'max_depth': 10, 'subsample': 0.6570681519289914}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:41:20,828] Trial 18 finished with value: 24.780636915252277 and parameters: {'n_estimators': 183, 'learning_rate': 0.11630530685587769, 'max_depth': 8, 'subsample': 0.9979337709200977}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:46:48,111] Trial 19 finished with value: 24.394817077379095 and parameters: {'n_estimators': 141, 'learning_rate': 0.04628091889753465, 'max_depth': 8, 'subsample': 0.6975463608177177}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 22:55:47,002] Trial 20 finished with value: 24.914685456519077 and parameters: {'n_estimators': 167, 'learning_rate': 0.11104959194836844, 'max_depth': 9, 'subsample': 0.8335174528035834}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:04:38,672] Trial 21 finished with value: 24.13776706236848 and parameters: {'n_estimators': 200, 'learning_rate': 0.015043029529636986, 'max_depth': 10, 'subsample': 0.6092453128648636}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:16:50,902] Trial 22 finished with value: 24.32091497091605 and parameters: {'n_estimators': 190, 'learning_rate': 0.04693073105470563, 'max_depth': 10, 'subsample': 0.6318644624547439}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:30:20,160] Trial 23 finished with value: 24.08584722107556 and parameters: {'n_estimators': 199, 'learning_rate': 0.01054758798381836, 'max_depth': 10, 'subsample': 0.6695609907802731}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:37:30,435] Trial 24 finished with value: 24.241532474946617 and parameters: {'n_estimators': 183, 'learning_rate': 0.0582853442007089, 'max_depth': 9, 'subsample': 0.6725493681050817}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:41:44,815] Trial 25 finished with value: 24.18640518409273 and parameters: {'n_estimators': 140, 'learning_rate': 0.010416743559283192, 'max_depth': 8, 'subsample': 0.7168209105563783}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:47:21,879] Trial 26 finished with value: 24.68229769654465 and parameters: {'n_estimators': 161, 'learning_rate': 0.09317785986840528, 'max_depth': 10, 'subsample': 0.633915892134137}. Best is trial 10 with value: 24.049716433620347.\n",
      "[I 2025-07-02 23:51:36,702] Trial 27 finished with value: 23.9829363544403 and parameters: {'n_estimators': 188, 'learning_rate': 0.032074108041256585, 'max_depth': 6, 'subsample': 0.6650326602468657}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-02 23:56:13,041] Trial 28 finished with value: 25.05169238565896 and parameters: {'n_estimators': 178, 'learning_rate': 0.13053768019652556, 'max_depth': 6, 'subsample': 0.7350242646327633}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:01:02,766] Trial 29 finished with value: 24.21535127214425 and parameters: {'n_estimators': 188, 'learning_rate': 0.034900955378672806, 'max_depth': 6, 'subsample': 0.7668471497152204}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:05:03,200] Trial 30 finished with value: 24.73372345635265 and parameters: {'n_estimators': 171, 'learning_rate': 0.08991632719454601, 'max_depth': 6, 'subsample': 0.6936545686009243}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:10:13,464] Trial 31 finished with value: 24.116810163104322 and parameters: {'n_estimators': 199, 'learning_rate': 0.02842885580750141, 'max_depth': 7, 'subsample': 0.6583699170049885}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:13:47,998] Trial 32 finished with value: 24.17043232964135 and parameters: {'n_estimators': 188, 'learning_rate': 0.0528656174884401, 'max_depth': 5, 'subsample': 0.6781280396715361}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:16:28,282] Trial 33 finished with value: 24.19371221782976 and parameters: {'n_estimators': 86, 'learning_rate': 0.03019456309953451, 'max_depth': 9, 'subsample': 0.6335173062855799}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:24:21,709] Trial 34 finished with value: 24.69538759267143 and parameters: {'n_estimators': 192, 'learning_rate': 0.06733522266759914, 'max_depth': 10, 'subsample': 0.7529088284421523}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:28:48,831] Trial 35 finished with value: 24.12016012408349 and parameters: {'n_estimators': 165, 'learning_rate': 0.024926836618965935, 'max_depth': 7, 'subsample': 0.711691050659519}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:34:20,427] Trial 36 finished with value: 26.64706748445023 and parameters: {'n_estimators': 175, 'learning_rate': 0.27615213725073373, 'max_depth': 9, 'subsample': 0.6494166811584576}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:35:16,435] Trial 37 finished with value: 24.170873913284222 and parameters: {'n_estimators': 55, 'learning_rate': 0.05910779226136488, 'max_depth': 4, 'subsample': 0.6907728152419201}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:39:20,213] Trial 38 finished with value: 24.188614612668477 and parameters: {'n_estimators': 154, 'learning_rate': 0.010252344382231715, 'max_depth': 8, 'subsample': 0.6212942757794473}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:43:20,983] Trial 39 finished with value: 24.373521541078702 and parameters: {'n_estimators': 183, 'learning_rate': 0.0945531881143298, 'max_depth': 5, 'subsample': 0.7769960791956251}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:46:30,092] Trial 40 finished with value: 24.044889553562808 and parameters: {'n_estimators': 135, 'learning_rate': 0.03949457975277605, 'max_depth': 6, 'subsample': 0.7263960034896364}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:49:51,891] Trial 41 finished with value: 24.12992177270231 and parameters: {'n_estimators': 131, 'learning_rate': 0.03734808786123725, 'max_depth': 6, 'subsample': 0.7284726987318306}. Best is trial 27 with value: 23.9829363544403.\n",
      "[I 2025-07-03 00:52:18,327] Trial 42 finished with value: 23.970897408890952 and parameters: {'n_estimators': 107, 'learning_rate': 0.024248664771382468, 'max_depth': 6, 'subsample': 0.6862536439021178}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 00:54:41,072] Trial 43 finished with value: 24.580417692698454 and parameters: {'n_estimators': 100, 'learning_rate': 0.08375241796692318, 'max_depth': 6, 'subsample': 0.7078292564788885}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 00:57:29,510] Trial 44 finished with value: 24.209368116263953 and parameters: {'n_estimators': 120, 'learning_rate': 0.06007876199224586, 'max_depth': 5, 'subsample': 0.7495609153738376}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 01:00:17,867] Trial 45 finished with value: 25.73096831848819 and parameters: {'n_estimators': 110, 'learning_rate': 0.18161903783090871, 'max_depth': 7, 'subsample': 0.6828139962711738}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 01:01:36,584] Trial 46 finished with value: 24.07235831256346 and parameters: {'n_estimators': 94, 'learning_rate': 0.02467917599747994, 'max_depth': 4, 'subsample': 0.6510460129906388}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 01:02:59,330] Trial 47 finished with value: 24.186578726223168 and parameters: {'n_estimators': 82, 'learning_rate': 0.04292521074333315, 'max_depth': 5, 'subsample': 0.6201615704825596}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 01:05:57,326] Trial 48 finished with value: 24.40167447717788 and parameters: {'n_estimators': 114, 'learning_rate': 0.07522344294049127, 'max_depth': 6, 'subsample': 0.7254277805262422}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 01:10:02,599] Trial 49 finished with value: 24.150560752459192 and parameters: {'n_estimators': 131, 'learning_rate': 0.02161953784597577, 'max_depth': 7, 'subsample': 0.8109811684851571}. Best is trial 42 with value: 23.970897408890952.\n",
      "[I 2025-07-03 01:10:02,599] A new study created in memory with name: no-name-481ef69c-1a54-4aaa-820c-e8e6b5ad84d1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting done. Best RMSE: 23.9709\n",
      "Starting tuning for HistGradientBoosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 01:10:42,954] Trial 0 finished with value: 24.19766460772646 and parameters: {'max_iter': 176, 'learning_rate': 0.030872438208021824, 'max_leaf_nodes': 39, 'min_samples_leaf': 4, 'l2_regularization': 0.9457567277456062}. Best is trial 0 with value: 24.19766460772646.\n",
      "[I 2025-07-03 01:11:08,234] Trial 1 finished with value: 24.398340617607438 and parameters: {'max_iter': 101, 'learning_rate': 0.038068015636762494, 'max_leaf_nodes': 92, 'min_samples_leaf': 16, 'l2_regularization': 0.8995387713396117}. Best is trial 0 with value: 24.19766460772646.\n",
      "[I 2025-07-03 01:11:35,410] Trial 2 finished with value: 25.385855553282102 and parameters: {'max_iter': 159, 'learning_rate': 0.2024811763982671, 'max_leaf_nodes': 38, 'min_samples_leaf': 18, 'l2_regularization': 0.21828126220966937}. Best is trial 0 with value: 24.19766460772646.\n",
      "[I 2025-07-03 01:11:46,156] Trial 3 finished with value: 24.062400106506413 and parameters: {'max_iter': 133, 'learning_rate': 0.03628132200566712, 'max_leaf_nodes': 15, 'min_samples_leaf': 19, 'l2_regularization': 0.21990759063138954}. Best is trial 3 with value: 24.062400106506413.\n",
      "[I 2025-07-03 01:12:06,566] Trial 4 finished with value: 24.82372164655404 and parameters: {'max_iter': 76, 'learning_rate': 0.13883923455666766, 'max_leaf_nodes': 52, 'min_samples_leaf': 10, 'l2_regularization': 0.558492420650032}. Best is trial 3 with value: 24.062400106506413.\n",
      "[I 2025-07-03 01:12:30,134] Trial 5 finished with value: 25.303247996055376 and parameters: {'max_iter': 98, 'learning_rate': 0.22373446227560576, 'max_leaf_nodes': 58, 'min_samples_leaf': 17, 'l2_regularization': 0.36039823223160905}. Best is trial 3 with value: 24.062400106506413.\n",
      "[I 2025-07-03 01:14:15,803] Trial 6 finished with value: 24.336719332495587 and parameters: {'max_iter': 200, 'learning_rate': 0.02604438382469216, 'max_leaf_nodes': 89, 'min_samples_leaf': 3, 'l2_regularization': 0.8755733750685396}. Best is trial 3 with value: 24.062400106506413.\n",
      "[I 2025-07-03 01:14:44,643] Trial 7 finished with value: 24.67697439177173 and parameters: {'max_iter': 106, 'learning_rate': 0.1003594392843595, 'max_leaf_nodes': 86, 'min_samples_leaf': 15, 'l2_regularization': 0.4648799852202957}. Best is trial 3 with value: 24.062400106506413.\n",
      "[I 2025-07-03 01:15:42,960] Trial 8 finished with value: 25.473234211297576 and parameters: {'max_iter': 188, 'learning_rate': 0.2702834519679739, 'max_leaf_nodes': 56, 'min_samples_leaf': 4, 'l2_regularization': 0.4658273770299628}. Best is trial 3 with value: 24.062400106506413.\n",
      "[I 2025-07-03 01:15:56,735] Trial 9 finished with value: 23.991171532257916 and parameters: {'max_iter': 106, 'learning_rate': 0.029422234367770528, 'max_leaf_nodes': 22, 'min_samples_leaf': 7, 'l2_regularization': 0.3547772992372752}. Best is trial 9 with value: 23.991171532257916.\n",
      "[I 2025-07-03 01:16:00,886] Trial 10 finished with value: 24.230614978321693 and parameters: {'max_iter': 50, 'learning_rate': 0.10567369187227255, 'max_leaf_nodes': 10, 'min_samples_leaf': 9, 'l2_regularization': 0.009388733322639009}. Best is trial 9 with value: 23.991171532257916.\n",
      "[I 2025-07-03 01:16:09,712] Trial 11 finished with value: 24.092789009041248 and parameters: {'max_iter': 139, 'learning_rate': 0.07613864872927621, 'max_leaf_nodes': 11, 'min_samples_leaf': 7, 'l2_regularization': 0.185098529135989}. Best is trial 9 with value: 23.991171532257916.\n",
      "[I 2025-07-03 01:16:28,059] Trial 12 finished with value: 24.316845947658585 and parameters: {'max_iter': 135, 'learning_rate': 0.06962658648329753, 'max_leaf_nodes': 26, 'min_samples_leaf': 13, 'l2_regularization': 0.680821280956024}. Best is trial 9 with value: 23.991171532257916.\n",
      "[I 2025-07-03 01:16:43,237] Trial 13 finished with value: 24.93751639938771 and parameters: {'max_iter': 121, 'learning_rate': 0.15544437582906642, 'max_leaf_nodes': 26, 'min_samples_leaf': 20, 'l2_regularization': 0.2486007585997005}. Best is trial 9 with value: 23.991171532257916.\n",
      "[I 2025-07-03 01:17:01,691] Trial 14 finished with value: 23.95466554603623 and parameters: {'max_iter': 157, 'learning_rate': 0.024098114722116492, 'max_leaf_nodes': 21, 'min_samples_leaf': 7, 'l2_regularization': 0.10845649645721436}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:17:59,724] Trial 15 finished with value: 24.730233014992073 and parameters: {'max_iter': 159, 'learning_rate': 0.14825709336963955, 'max_leaf_nodes': 74, 'min_samples_leaf': 7, 'l2_regularization': 0.07672028281526111}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:18:26,549] Trial 16 finished with value: 24.365181407529214 and parameters: {'max_iter': 159, 'learning_rate': 0.06419191259177538, 'max_leaf_nodes': 29, 'min_samples_leaf': 1, 'l2_regularization': 0.3664676550281927}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:18:44,627] Trial 17 finished with value: 24.592640043442337 and parameters: {'max_iter': 80, 'learning_rate': 0.10835837550458768, 'max_leaf_nodes': 44, 'min_samples_leaf': 12, 'l2_regularization': 0.6301249255778469}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:18:59,370] Trial 18 finished with value: 24.10730985174012 and parameters: {'max_iter': 120, 'learning_rate': 0.01539058607997983, 'max_leaf_nodes': 21, 'min_samples_leaf': 7, 'l2_regularization': 0.10941104913287858}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:19:50,884] Trial 19 finished with value: 24.944770357368334 and parameters: {'max_iter': 148, 'learning_rate': 0.19470967896154273, 'max_leaf_nodes': 75, 'min_samples_leaf': 9, 'l2_regularization': 0.3558474513179729}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:20:06,908] Trial 20 finished with value: 24.26564946620376 and parameters: {'max_iter': 81, 'learning_rate': 0.05599271640316267, 'max_leaf_nodes': 34, 'min_samples_leaf': 6, 'l2_regularization': 0.2918879565653425}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:20:20,420] Trial 21 finished with value: 24.11449402042181 and parameters: {'max_iter': 132, 'learning_rate': 0.014461154891378808, 'max_leaf_nodes': 18, 'min_samples_leaf': 12, 'l2_regularization': 0.13495361389263993}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:20:33,448] Trial 22 finished with value: 24.271439045182117 and parameters: {'max_iter': 148, 'learning_rate': 0.04891100341698545, 'max_leaf_nodes': 17, 'min_samples_leaf': 20, 'l2_regularization': 0.006485408898407624}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:20:46,243] Trial 23 finished with value: 24.435050980658986 and parameters: {'max_iter': 122, 'learning_rate': 0.08433905126743185, 'max_leaf_nodes': 18, 'min_samples_leaf': 5, 'l2_regularization': 0.2948930202554603}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:21:27,547] Trial 24 finished with value: 24.1815580847794 and parameters: {'max_iter': 172, 'learning_rate': 0.044993099636606845, 'max_leaf_nodes': 46, 'min_samples_leaf': 9, 'l2_regularization': 0.40346051065141686}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:21:49,889] Trial 25 finished with value: 24.336226116153036 and parameters: {'max_iter': 114, 'learning_rate': 0.010619982045738286, 'max_leaf_nodes': 32, 'min_samples_leaf': 1, 'l2_regularization': 0.18102780021415377}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:21:57,901] Trial 26 finished with value: 24.47135028836079 and parameters: {'max_iter': 145, 'learning_rate': 0.09112065513347917, 'max_leaf_nodes': 10, 'min_samples_leaf': 14, 'l2_regularization': 0.08181475751971358}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:22:08,463] Trial 27 finished with value: 24.637769467299474 and parameters: {'max_iter': 90, 'learning_rate': 0.13209459795876355, 'max_leaf_nodes': 21, 'min_samples_leaf': 11, 'l2_regularization': 0.2743069361968744}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:22:31,109] Trial 28 finished with value: 25.279347283199794 and parameters: {'max_iter': 63, 'learning_rate': 0.296907899211505, 'max_leaf_nodes': 69, 'min_samples_leaf': 8, 'l2_regularization': 0.7644489289316182}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:22:55,999] Trial 29 finished with value: 24.08458868780214 and parameters: {'max_iter': 110, 'learning_rate': 0.03345656639987035, 'max_leaf_nodes': 39, 'min_samples_leaf': 4, 'l2_regularization': 0.1462047895734375}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:23:18,804] Trial 30 finished with value: 24.475648163629387 and parameters: {'max_iter': 167, 'learning_rate': 0.1268599919538301, 'max_leaf_nodes': 25, 'min_samples_leaf': 5, 'l2_regularization': 0.5186797886540399}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:23:44,776] Trial 31 finished with value: 24.23270082463106 and parameters: {'max_iter': 113, 'learning_rate': 0.035669578900014834, 'max_leaf_nodes': 39, 'min_samples_leaf': 3, 'l2_regularization': 0.15699750640011706}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:24:10,981] Trial 32 finished with value: 24.147538890363723 and parameters: {'max_iter': 128, 'learning_rate': 0.034573607918598925, 'max_leaf_nodes': 35, 'min_samples_leaf': 3, 'l2_regularization': 0.05702718754397506}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:24:20,573] Trial 33 finished with value: 24.119877639031348 and parameters: {'max_iter': 97, 'learning_rate': 0.057278358192812566, 'max_leaf_nodes': 16, 'min_samples_leaf': 5, 'l2_regularization': 0.20059320424474014}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:24:41,483] Trial 34 finished with value: 24.4613652660041 and parameters: {'max_iter': 107, 'learning_rate': 0.028859411016724866, 'max_leaf_nodes': 44, 'min_samples_leaf': 18, 'l2_regularization': 0.22775016928470032}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:25:07,170] Trial 35 finished with value: 24.336697375785 and parameters: {'max_iter': 91, 'learning_rate': 0.04544428286499354, 'max_leaf_nodes': 50, 'min_samples_leaf': 6, 'l2_regularization': 0.3176244791178163}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:25:30,336] Trial 36 finished with value: 24.064801228614634 and parameters: {'max_iter': 141, 'learning_rate': 0.024173438716273872, 'max_leaf_nodes': 30, 'min_samples_leaf': 10, 'l2_regularization': 0.9778406971563314}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:25:54,798] Trial 37 finished with value: 25.043436420082895 and parameters: {'max_iter': 155, 'learning_rate': 0.18337222119973326, 'max_leaf_nodes': 30, 'min_samples_leaf': 8, 'l2_regularization': 0.9555423985678295}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:27:13,054] Trial 38 finished with value: 25.3783193925408 and parameters: {'max_iter': 190, 'learning_rate': 0.23533369558547307, 'max_leaf_nodes': 100, 'min_samples_leaf': 10, 'l2_regularization': 0.8827146734646683}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:27:24,311] Trial 39 finished with value: 23.974038497946488 and parameters: {'max_iter': 140, 'learning_rate': 0.02419244119623889, 'max_leaf_nodes': 14, 'min_samples_leaf': 11, 'l2_regularization': 0.7696336659979408}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:27:37,425] Trial 40 finished with value: 24.25755592435555 and parameters: {'max_iter': 168, 'learning_rate': 0.06699403875995652, 'max_leaf_nodes': 15, 'min_samples_leaf': 16, 'l2_regularization': 0.7980209308734495}. Best is trial 14 with value: 23.95466554603623.\n",
      "[I 2025-07-03 01:27:55,566] Trial 41 finished with value: 23.954302868269505 and parameters: {'max_iter': 152, 'learning_rate': 0.02177424276932133, 'max_leaf_nodes': 22, 'min_samples_leaf': 11, 'l2_regularization': 0.7968130782924613}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:28:13,754] Trial 42 finished with value: 24.254571283667893 and parameters: {'max_iter': 152, 'learning_rate': 0.011468347177512953, 'max_leaf_nodes': 22, 'min_samples_leaf': 14, 'l2_regularization': 0.7447394155986407}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:28:26,693] Trial 43 finished with value: 24.013432619773646 and parameters: {'max_iter': 181, 'learning_rate': 0.0239874452418455, 'max_leaf_nodes': 13, 'min_samples_leaf': 11, 'l2_regularization': 0.592697390624364}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:28:40,460] Trial 44 finished with value: 24.026043293928232 and parameters: {'max_iter': 180, 'learning_rate': 0.026038135900838873, 'max_leaf_nodes': 14, 'min_samples_leaf': 11, 'l2_regularization': 0.6528402156640004}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:29:02,615] Trial 45 finished with value: 24.442008988982884 and parameters: {'max_iter': 177, 'learning_rate': 0.0806239686495023, 'max_leaf_nodes': 25, 'min_samples_leaf': 13, 'l2_regularization': 0.5546657765264627}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:29:15,711] Trial 46 finished with value: 24.098461732714814 and parameters: {'max_iter': 188, 'learning_rate': 0.04959759926327449, 'max_leaf_nodes': 13, 'min_samples_leaf': 12, 'l2_regularization': 0.8338795206372877}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:29:35,479] Trial 47 finished with value: 24.033361641591647 and parameters: {'max_iter': 164, 'learning_rate': 0.02169840101125251, 'max_leaf_nodes': 22, 'min_samples_leaf': 11, 'l2_regularization': 0.7116612708023465}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:29:46,201] Trial 48 finished with value: 23.990053103365256 and parameters: {'max_iter': 193, 'learning_rate': 0.04224738276792282, 'max_leaf_nodes': 10, 'min_samples_leaf': 8, 'l2_regularization': 0.6036128449193647}. Best is trial 41 with value: 23.954302868269505.\n",
      "[I 2025-07-03 01:30:48,119] Trial 49 finished with value: 24.331449849081565 and parameters: {'max_iter': 194, 'learning_rate': 0.11805925547052505, 'max_leaf_nodes': 64, 'min_samples_leaf': 8, 'l2_regularization': 0.9222511318574129}. Best is trial 41 with value: 23.954302868269505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting done. Best RMSE: 23.9543\n"
     ]
    }
   ],
   "source": [
    "study_results = {}\n",
    "models = {\n",
    "    \"Ridge\": tune_ridge,\n",
    "    \"Lasso\": tune_lasso,\n",
    "    \"ElasticNet\": tune_elasticnet,\n",
    "    \"SVR\": tune_svr,\n",
    "    \"RandomForest\": tune_rf,\n",
    "    \"GradientBoosting\": tune_gbr,\n",
    "    \"HistGradientBoosting\": tune_histgbr\n",
    "}\n",
    "\n",
    "for name, objective in models.items():\n",
    "    print(f\"Starting tuning for {name}...\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=50) \n",
    "    study_results[name] = {\n",
    "        \"best_score\": study.best_value,\n",
    "        \"best_params\": study.best_params\n",
    "    }\n",
    "    print(f\"{name} done. Best RMSE: {study.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4befa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_model(name, params):\n",
    "    if name == \"Ridge\":\n",
    "        return make_pipeline(StandardScaler(), Ridge(**params))\n",
    "    elif name == \"Lasso\":\n",
    "        return make_pipeline(StandardScaler(), Lasso(max_iter=10000, **params))\n",
    "    elif name == \"ElasticNet\":\n",
    "        return make_pipeline(StandardScaler(), ElasticNet(max_iter=10000, **params))\n",
    "    elif name == \"SVR\":\n",
    "        return make_pipeline(StandardScaler(), SVR(**params))\n",
    "    elif name == \"RandomForest\":\n",
    "        return RandomForestRegressor(random_state=42, n_jobs=-1, **params)\n",
    "    elif name == \"GradientBoosting\":\n",
    "        return GradientBoostingRegressor(random_state=42, **params)\n",
    "    elif name == \"HistGradientBoosting\":\n",
    "        return HistGradientBoostingRegressor(random_state=42, **params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {name}\")\n",
    "\n",
    "model_names = []\n",
    "rmse_scores = []\n",
    "\n",
    "for name, res in study_results.items():\n",
    "    model = get_model(name, res['best_params'])\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error')\n",
    "    mean_rmse = -scores.mean()\n",
    "    model_names.append(name)\n",
    "    rmse_scores.append(mean_rmse)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(model_names, rmse_scores, color='skyblue')\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"5-Fold CV RMSE Comparison\")\n",
    "\n",
    "for bar, rmse in zip(bars, rmse_scores):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f\"{rmse:.4f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.ylim(0, max(rmse_scores)*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5d79d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Training Set RMSE Evaluation ===\n",
      "Ridge                     RMSE on train set: 18.9621\n",
      "Lasso                     RMSE on train set: 22.3037\n",
      "ElasticNet                RMSE on train set: 22.1790\n",
      "SVR                       RMSE on train set: 22.5239\n",
      "RandomForest              RMSE on train set: 13.6115\n",
      "GradientBoosting          RMSE on train set: 13.0859\n",
      "HistGradientBoosting      RMSE on train set: 13.9650\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Training Set RMSE Evaluation ===\")\n",
    "for name, res in study_results.items():\n",
    "    model = get_model(name, res['best_params'])\n",
    "    model.fit(X, y)\n",
    "    preds = model.predict(X)\n",
    "    mse = mean_squared_error(y, preds) \n",
    "    rmse = np.sqrt(mse) \n",
    "    print(f\"{name:25s} RMSE on train set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d4ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
